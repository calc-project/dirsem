---
title: "Directionl tendencies in semantic shift"
author: "Katja Bocklage, Anna Di Natale, Annika Tjuka, Matthias Pache, Johann-Mattis List"
date: "2023-12-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading required libraries
```{r}
library(jsonlite) ##version 1.8.8
library(dplyr) ##version 1.1.4
```

Loading data
```{r}
winter_data<-read.csv('data\\Winter-2022-98.tsv',sep='\t') ##data about over marking from Winter
affix_colex<-read.csv('data\\affix-colexifications.tsv',sep='\t')
ground_truth<-read.csv('data\\gold_standard_Urban.csv',sep=';')  ##data about semantic shift from Urban
ground_truth<-ground_truth[-c(20,35,15,30,1,25,11,29,3,27,8,28,2,26,16,33,17,32,18,34),] ##removing the instances of semantic shift for which the direction is not clear (from Urban 2011)
dss<-read.csv('data\\dss.tsv',sep='\t') ##semantic shift from DatSemShift
```

DATA CLEANING

Restructuring Winter data in a dataframe
```{r}
winter_df<-data.frame(stringsAsFactors = F) ##initialising dataframe

for (i in seq (1,nrow(winter_data))) ##loop on imported data
{
  concept<-winter_data$ENGLISH[i]
  ##ordering sources
  sources<-fromJSON(winter_data$SOURCE_CONCEPTS[i])
  for(j in seq(1,nrow(sources)))
  {
    source<-sources$NAME[j]
    df<-data.frame(source=source,target=concept,
               overt_marking=sources$OvertMarking[j],stringsAsFactors = F)
    winter_df<-rbind(winter_df,df)
  }
  ##ordering targets
  targets<-fromJSON(winter_data$TARGET_CONCEPTS[i])
    for(j in seq(1,nrow(targets)))
  {
    target<-targets$NAME[j]
    df<-data.frame(source=concept,target=target,
               overt_marking=targets$OvertMarking[j],stringsAsFactors = F)
    winter_df<-rbind(winter_df,df)
  }
}
winter_df<-winter_df[-which(duplicated(winter_df)),] ##removing duplicates
rownames(winter_df)<-seq(1,nrow(winter_df)) ##renaming rows

```

Restructuring affix colex data
```{r}
affix_colex$Source<-tolower(affix_colex$Source)
affix_colex$Target<-tolower(affix_colex$Target)
affix_colex <- affix_colex %>% rename ('target' = 'Target', 'source'='Source')
affix_colex$Target_Concepticon_ID<-NULL
affix_colex$Source_Concepticon_ID<-NULL
```

Restructuring DatSemShift
```{r}
dss<-dss%>%rename(target=Target_Gloss,source=Source_Gloss)
dss<-dss[,c(4,6:10)]
dss$source<-tolower(dss$source)
dss$target<-tolower(dss$target)
```

ANALYSES

Winter data and gold standard from Urban
```{r}
winter_df<-left_join(winter_df,winter_df,by=c("source"="target","target"="source")) ##adding opposite overt marking
##renaming column
winter_df<-winter_df%>%rename("opposite_overt_marking"="overt_marking.y")
winter_df<-winter_df%>%rename("overt_marking"="overt_marking.x")

ground_truth$correlation<-NULL

source("check_prediction.R")
# output<-check_prediction(winter_df,ground_truth,"strict")
output<-check_prediction(winter_df,ground_truth,"relaxed")
paste("Number instances accepted:", output$confirmed )
paste("Number instances rejected:", output$not_confirmed)
paste("N:", output$N)
paste("Precision:",round(output$prec,digits=2))
paste("Recall:",round(output$rec,digits=2))
paste("F1:",round(output$F1,digits=2))

```

Affix colex and gold standard from Urban
```{r}
merged_df<-left_join(affix_colex,affix_colex,by=c("source"="target","target"="source"))

##analysis with language weights
##renaming columns (languages)
merged_df<-merged_df%>%rename("overt_marking"="Affix_Col_Languages.x")
merged_df<-merged_df%>%rename("opposite_overt_marking"="Affix_Col_Languages.y")
##removing useless columns
merged_df$Affix_Col_Families.x<-NULL
merged_df$Affix_Col_Families.y<-NULL

##analysis with family weights
# ##renaming columns (families)
# merged_df<-merged_df%>%rename("overt_marking"="Affix_Col_Families.x")
# merged_df<-merged_df%>%rename("opposite_overt_marking"="Affix_Col_Families.y")
# merged_df$Affix_Col_Languages.x<-NULL
# merged_df$Affix_Col_Languages.y<-NULL


##adding 0s where we have NAs
merged_df$opposite_overt_marking[is.na(merged_df$opposite_overt_marking)]<-0
merged_df$overt_marking[is.na(merged_df$overt_marking)]<-0

ground_truth$correlation<-NULL

source("check_prediction.R")
# output<-check_prediction(merged_df,ground_truth,"strict")
output<-check_prediction(merged_df,ground_truth,"relaxed")
paste("Number instances accepted:", output$confirmed )
paste("Number instances rejected:", output$not_confirmed)
paste("N:", output$N)
paste("Precision:",round(output$prec,digits=2))
paste("Recall:",round(output$rec,digits=2))
paste("F1:",round(output$F1,digits=2))

```

Affix colex and DatSemShift as gold standard
```{r}
sel<-dss[which(dss$Undirected_Polysemy==0&dss$Undirected_Derivation==0),] ###selecting only entries for which directionality is certain
sel$Undirected_Polysemy<-NULL ##removing useless column
sel$Undirected_Derivation<-NULL ##removing useless column
sel$Derivation<-NULL
sel<-sel[which(sel$Polysemy>0),] ###selecting only the ones that have polysemy evidence

##removing duplicates (rows for which we have evidence in both directions)
rownames(sel)<-seq(1,nrow(sel))
dupl<-which(duplicated(data.frame(t(apply(sel[1:2], 1, sort)))))
to_remove<-dupl
for(i in dupl)
{
  s<-sel$Source[i]
  t<-sel$Target[i]
  to_remove<-c(to_remove,which(sel$Target==s & sel$Source==t))
}
sel<-sel[-to_remove,]
rownames(sel)<-seq(1,nrow(sel))

sel$Polysemy<-NULL ##removing useless columns

merged_df<-left_join(affix_colex,affix_colex,by=c("source"="target","target"="source"))

##analysis with language weights
##renaming columns (languages)
merged_df<-merged_df%>%rename("overt_marking"="Affix_Col_Languages.x")
merged_df<-merged_df%>%rename("opposite_overt_marking"="Affix_Col_Languages.y")
##removing useless columns
merged_df$Affix_Col_Families.x<-NULL
merged_df$Affix_Col_Families.y<-NULL

##analysis with family weights
# ##renaming columns (families)
# merged_df<-merged_df%>%rename("overt_marking"="Affix_Col_Families.x")
# merged_df<-merged_df%>%rename("opposite_overt_marking"="Affix_Col_Families.y")
# ##removing useless columns
# merged_df$Affix_Col_Languages.x<-NULL
#merged_df$Affix_Col_Languages.y<-NULL


##adding 0s where we have NAs
merged_df$opposite_overt_marking[is.na(merged_df$opposite_overt_marking)]<-0
merged_df$overt_marking[is.na(merged_df$overt_marking)]<-0


source("check_prediction.R")
# output<-check_prediction(merged_df,sel,"strict")
output<-check_prediction(merged_df,sel,"relaxed")
paste("Number instances accepted:", output$confirmed )
paste("Number instances rejected:", output$not_confirmed)
paste("N:", output$N)
paste("Precision:",round(output$prec,digits=2))
paste("Recall:",round(output$rec,digits=2))
paste("F1:",round(output$F1,digits=2))

```

